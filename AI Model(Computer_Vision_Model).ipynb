{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 3505874,
          "sourceType": "datasetVersion",
          "datasetId": 2110080,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "SGD_Draft_Assignment_2_CNN(Shallow)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MH-1294/ML_DL/blob/main/AI%20Model(Computer_Vision_Model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "faysalmiah1721758_potato_dataset_path = kagglehub.dataset_download('faysalmiah1721758/potato-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "3anBWmot_yYp"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kagglehub\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Step 1: Download dataset\n",
        "faysalmiah1721758_potato_dataset_path = kagglehub.dataset_download('faysalmiah1721758/potato-dataset')\n",
        "print(\"Data download complete.\")\n",
        "\n",
        "DATASET_DIR = faysalmiah1721758_potato_dataset_path\n",
        "\n",
        "# Step 2: List image paths and labels\n",
        "class_names = sorted(os.listdir(DATASET_DIR))\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for label_index, class_name in enumerate(class_names):\n",
        "    class_dir = os.path.join(DATASET_DIR, class_name)\n",
        "    for fname in os.listdir(class_dir):\n",
        "        file_paths.append(os.path.join(class_dir, fname))\n",
        "        labels.append(label_index)\n",
        "\n",
        "file_paths = np.array(file_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Step 3: 80/10/10 split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    file_paths, labels, test_size=0.20, stratify=labels, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "# Step 4: Dataset loading function (with optional augmentation)\n",
        "IMAGE_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_dataset(file_paths, labels, augment=False, shuffle=True):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "    def process_image(path, label):\n",
        "        image = tf.io.read_file(path)\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, IMAGE_SIZE)\n",
        "        image = image / 255.0  # Normalize\n",
        "\n",
        "        if augment:\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "            image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "            image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "\n",
        "        return image, tf.one_hot(label, depth=len(class_names))\n",
        "\n",
        "    ds = path_ds.map(process_image, num_parallel_calls=AUTOTUNE)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=1000)\n",
        "\n",
        "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Step 5: Create datasets\n",
        "train_ds = load_dataset(X_train, y_train, augment=True)  # Enable if you want light augmentation\n",
        "val_ds = load_dataset(X_val, y_val, augment=False)\n",
        "test_ds = load_dataset(X_test, y_test, augment=False)\n",
        "\n",
        "print(\"Class names:\", class_names)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-25T18:33:41.114862Z",
          "iopub.execute_input": "2025-10-25T18:33:41.115103Z",
          "iopub.status.idle": "2025-10-25T18:34:01.010498Z",
          "shell.execute_reply.started": "2025-10-25T18:33:41.115087Z",
          "shell.execute_reply": "2025-10-25T18:34:01.009725Z"
        },
        "id": "oT8Dc2Iq_yYt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_model(model, model_name, train_ds, val_ds, test_ds, class_names, epochs=30):\n",
        "    # Create folders\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "    os.makedirs('history', exist_ok=True)\n",
        "\n",
        "    # Unique model name\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    model_name = f\"{model_name}_{timestamp}\"\n",
        "    model_path = f\"models/{model_name}.h5\"\n",
        "    history_path = f\"history/{model_name}_history.pkl\"\n",
        "    plot_path = f\"history/{model_name}_plot.png\"\n",
        "    cm_path = f\"history/{model_name}_confusion_matrix.png\"\n",
        "\n",
        "    # Compute class weights based on class imbalance\n",
        "    print(\"ðŸ” Computing class weights...\")\n",
        "    y_train = []\n",
        "    for _, labels in train_ds:\n",
        "        y_train.extend(np.argmax(labels.numpy(), axis=1))\n",
        "    class_weight = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.arange(len(class_names)),\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weight = dict(enumerate(class_weight))\n",
        "    print(f\"Class weights: {class_weight}\")\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stop, checkpoint],\n",
        "        class_weight=class_weight\n",
        "    )\n",
        "\n",
        "    # Save history\n",
        "    with open(history_path, 'wb') as f:\n",
        "        pickle.dump(history.history, f)\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(test_ds)\n",
        "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Predict\n",
        "    y_true, y_pred = [], []\n",
        "    for images, labels in test_ds:\n",
        "        preds = model.predict(images)\n",
        "        y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "        y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))  # increase size to fix overlap\n",
        "    disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=45)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(cm_path)\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy & Loss Plots\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(plot_path)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nBest model saved to: {model_path}\")\n",
        "    print(f\"Training history saved to: {history_path}\")\n",
        "    print(f\"Training plots saved to: {plot_path}\")\n",
        "    print(f\"Confusion matrix saved to: {cm_path}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:11:27.038948Z",
          "iopub.execute_input": "2025-07-01T01:11:27.039188Z",
          "iopub.status.idle": "2025-07-01T01:11:27.055106Z",
          "shell.execute_reply.started": "2025-07-01T01:11:27.03916Z",
          "shell.execute_reply": "2025-07-01T01:11:27.054359Z"
        },
        "id": "VWNVk8Yx_yYu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_improved_cnn(input_shape=(256, 256, 3), num_classes=3):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Block 6\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:11:27.055904Z",
          "iopub.execute_input": "2025-07-01T01:11:27.05623Z",
          "iopub.status.idle": "2025-07-01T01:11:27.073747Z",
          "shell.execute_reply.started": "2025-07-01T01:11:27.056203Z",
          "shell.execute_reply": "2025-07-01T01:11:27.072897Z"
        },
        "id": "HSZj48JC_yYw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the lightweight CNN model\n",
        "model = build_improved_cnn()\n",
        "\n",
        "# Train and evaluate\n",
        "train_and_evaluate_model(\n",
        "    model=model,\n",
        "    model_name=\"new_test_light_weight_CNN\",\n",
        "    train_ds=train_ds,\n",
        "    val_ds=val_ds,\n",
        "    test_ds=test_ds,\n",
        "    class_names=class_names,\n",
        "    epochs=50\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:11:27.075912Z",
          "iopub.execute_input": "2025-07-01T01:11:27.076109Z",
          "iopub.status.idle": "2025-07-01T01:13:10.829065Z",
          "shell.execute_reply.started": "2025-07-01T01:11:27.076094Z",
          "shell.execute_reply": "2025-07-01T01:13:10.828054Z"
        },
        "id": "nMXuUQE8_yYx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to make prediction on a single image\n",
        "def predict(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Shape: (1, height, width, 3)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100 * np.max(predictions[0]), 2)\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# Visualize predictions on a batch of test images\n",
        "plt.figure(figsize=(15, 15))\n",
        "for images, labels in test_ds.take(1):  # Take one batch from test dataset\n",
        "    for i in range(min(9, len(images))):  # Display 9 images or less if batch is smaller\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy())\n",
        "\n",
        "        predicted_class, confidence = predict(model, images[i].numpy())\n",
        "        actual_class = class_names[tf.argmax(labels[i]).numpy()] if len(labels[i].shape) > 0 and labels[i].shape[-1] > 1 else class_names[labels[i].numpy()]\n",
        "\n",
        "        plt.title(f\"Actual: {actual_class}\\nPredicted: {predicted_class}\\nConfidence: {confidence}%\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:10.829788Z",
          "iopub.execute_input": "2025-07-01T01:13:10.829979Z",
          "iopub.status.idle": "2025-07-01T01:13:13.904069Z",
          "shell.execute_reply.started": "2025-07-01T01:13:10.829963Z",
          "shell.execute_reply": "2025-07-01T01:13:13.903002Z"
        },
        "id": "iFwfyPkw_yYx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/kaggle/working/leaf_disease_model.h5\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:13.904981Z",
          "iopub.execute_input": "2025-07-01T01:13:13.905213Z",
          "iopub.status.idle": "2025-07-01T01:13:13.962915Z",
          "shell.execute_reply.started": "2025-07-01T01:13:13.905195Z",
          "shell.execute_reply": "2025-07-01T01:13:13.962078Z"
        },
        "id": "iviI2kI__yYx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/kaggle/working/models/lightweight_cnn_20250625-011416.h5\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:13.963791Z",
          "iopub.execute_input": "2025-07-01T01:13:13.96401Z",
          "iopub.status.idle": "2025-07-01T01:13:14.018178Z",
          "shell.execute_reply.started": "2025-07-01T01:13:13.963992Z",
          "shell.execute_reply": "2025-07-01T01:13:14.017284Z"
        },
        "id": "DsfpocQZ_yYx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        print(layer.name)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:14.018973Z",
          "iopub.execute_input": "2025-07-01T01:13:14.019239Z",
          "iopub.status.idle": "2025-07-01T01:13:14.023562Z",
          "shell.execute_reply.started": "2025-07-01T01:13:14.019216Z",
          "shell.execute_reply": "2025-07-01T01:13:14.022808Z"
        },
        "id": "LrAHfywf_yYy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "trusted": true,
        "id": "JIqeXroX_yYy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Select ONE test image (not a batch)\n",
        "for image, label in test_ds.unbatch().take(3):\n",
        "    input_image = image  # shape: [H, W, 3]\n",
        "    input_label = label\n",
        "    break\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:18:13.218152Z",
          "iopub.execute_input": "2025-07-01T02:18:13.218488Z",
          "iopub.status.idle": "2025-07-01T02:18:13.842249Z",
          "shell.execute_reply.started": "2025-07-01T02:18:13.218432Z",
          "shell.execute_reply": "2025-07-01T02:18:13.841393Z"
        },
        "id": "s5A5VPz8_yYy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the selected image\n",
        "input_height, input_width = model.input_shape[1], model.input_shape[2]\n",
        "image_resized = tf.image.resize(input_image, (input_height, input_width))\n",
        "\n",
        "# Ensure float32 and correct shape\n",
        "image_resized = tf.cast(image_resized, tf.float32)  # shape: [256, 256, 3]\n",
        "\n",
        "# Predict\n",
        "image_batch = tf.expand_dims(image_resized, axis=0)  # shape: [1, 256, 256, 3]\n",
        "preds = model.predict(image_batch, verbose=0)[0]\n",
        "pred_idx = np.argmax(preds)\n",
        "confidence = round(100 * preds[pred_idx], 2)\n",
        "pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "\n",
        "# Grad-CAM\n",
        "heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "\n",
        "# Prepare image for masking\n",
        "image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "if image_np.shape[-1] == 1:\n",
        "    image_np = np.repeat(image_np, 3, axis=-1)\n",
        "\n",
        "# Apply leaf mask\n",
        "leaf_mask = mask_leaf(image_np)\n",
        "heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n",
        "\n",
        "# Show visualization\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image_np)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(heatmap_resized, cmap='plasma')\n",
        "plt.title(\"Grad-CAM (Full)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(heatmap_masked, cmap='plasma')\n",
        "plt.title(\"Grad-CAM (Masked to Leaf)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:18:14.56084Z",
          "iopub.execute_input": "2025-07-01T02:18:14.561145Z",
          "iopub.status.idle": "2025-07-01T02:18:14.991436Z",
          "shell.execute_reply.started": "2025-07-01T02:18:14.561122Z",
          "shell.execute_reply": "2025-07-01T02:18:14.990693Z"
        },
        "id": "IFxkzhC6_yYz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Grad-CAM max:\", np.max(heatmap_resized))\n",
        "print(\"Masked Grad-CAM max:\", np.max(heatmap_masked))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:20:51.633532Z",
          "iopub.execute_input": "2025-07-01T02:20:51.634063Z",
          "iopub.status.idle": "2025-07-01T02:20:51.640729Z",
          "shell.execute_reply.started": "2025-07-01T02:20:51.634032Z",
          "shell.execute_reply": "2025-07-01T02:20:51.640099Z"
        },
        "id": "yzLhd-FG_yY0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Non-zero pixels (before masking):\", np.count_nonzero(heatmap_resized))\n",
        "print(\"Non-zero pixels (after masking):\", np.count_nonzero(heatmap_masked))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:22:15.874604Z",
          "iopub.execute_input": "2025-07-01T02:22:15.874923Z",
          "iopub.status.idle": "2025-07-01T02:22:15.879662Z",
          "shell.execute_reply.started": "2025-07-01T02:22:15.874902Z",
          "shell.execute_reply": "2025-07-01T02:22:15.878848Z"
        },
        "id": "5TTz4r7W_yY0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-means"
      ],
      "metadata": {
        "id": "bjbQhTn1_yY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def apply_three_way_kmeans(heatmap, n_clusters=3):\n",
        "    flat = heatmap.flatten().reshape(-1, 1)\n",
        "\n",
        "    # Avoid clustering error if image is flat\n",
        "    if np.std(flat) < 1e-5:\n",
        "        return np.zeros_like(heatmap, dtype=np.uint8)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto').fit(flat)\n",
        "    clustered = kmeans.labels_.reshape(heatmap.shape)\n",
        "\n",
        "    # Sort clusters by intensity\n",
        "    means = [np.mean(flat[kmeans.labels_ == i]) for i in range(n_clusters)]\n",
        "    sorted_indices = np.argsort(means)\n",
        "\n",
        "    label_map = np.zeros_like(clustered)\n",
        "    for new_label, original_label in enumerate(sorted_indices):\n",
        "        label_map[clustered == original_label] = new_label\n",
        "\n",
        "    return label_map.astype(np.uint8)  # 0 = background, 1 = uncertain, 2 = strong attention\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:25:08.20451Z",
          "iopub.execute_input": "2025-07-01T02:25:08.204834Z",
          "iopub.status.idle": "2025-07-01T02:25:08.210637Z",
          "shell.execute_reply.started": "2025-07-01T02:25:08.204813Z",
          "shell.execute_reply": "2025-07-01T02:25:08.20987Z"
        },
        "id": "VRdD8kFm_yY2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_clustered_attention(image_np, cluster_mask):\n",
        "    \"\"\"\n",
        "    Overlay 3 attention zones on top of original image.\n",
        "    \"\"\"\n",
        "    output = image_np.copy()\n",
        "\n",
        "    # Define RGB colors for each zone\n",
        "    colors = {\n",
        "        0: [180, 180, 180],  # gray = ignored\n",
        "        1: [255, 165, 0],    # orange = uncertain\n",
        "        2: [255, 0, 0]       # red = strong attention\n",
        "    }\n",
        "\n",
        "    for region, color in colors.items():\n",
        "        mask = (cluster_mask == region)\n",
        "        for c in range(3):\n",
        "            output[:, :, c] = np.where(\n",
        "                mask,\n",
        "                0.5 * output[:, :, c] + 0.5 * color[c],\n",
        "                output[:, :, c]\n",
        "            )\n",
        "\n",
        "    return output.astype(np.uint8)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:25:17.299252Z",
          "iopub.execute_input": "2025-07-01T02:25:17.299622Z",
          "iopub.status.idle": "2025-07-01T02:25:17.304726Z",
          "shell.execute_reply.started": "2025-07-01T02:25:17.299597Z",
          "shell.execute_reply": "2025-07-01T02:25:17.30388Z"
        },
        "id": "thVVqRMQ_yY3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply 3-way KMeans clustering to masked heatmap\n",
        "cluster_mask = apply_three_way_kmeans(heatmap_masked)\n",
        "cluster_mask = cv2.resize(cluster_mask.astype(np.uint8), (input_width, input_height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "# Overlay clustered attention zones\n",
        "overlayed_image = overlay_clustered_attention(image_np, cluster_mask)\n",
        "\n",
        "# Visualize final result\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlayed_image)\n",
        "plt.title(f\"3-Way Clustered Attention\\n(Predicted: {pred_label} | {confidence}%)\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:26:20.446214Z",
          "iopub.execute_input": "2025-07-01T02:26:20.446735Z",
          "iopub.status.idle": "2025-07-01T02:26:20.703787Z",
          "shell.execute_reply.started": "2025-07-01T02:26:20.446706Z",
          "shell.execute_reply": "2025-07-01T02:26:20.70312Z"
        },
        "id": "muqq3yVW_yY3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Function: Generate Grad-CAM\n",
        "def generate_gradcam(model, image, class_index, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(tf.expand_dims(image, axis=0))\n",
        "        loss = predictions[:, class_index]\n",
        "    grads = tape.gradient(loss, conv_outputs)[0]\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Function: Leaf Mask (HSV green filter)\n",
        "def mask_leaf(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    lower_green = np.array([25, 40, 40])\n",
        "    upper_green = np.array([85, 255, 255])\n",
        "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "    return mask\n",
        "\n",
        "# Function: 3-Way KMeans\n",
        "def apply_three_way_kmeans(heatmap, n_clusters=3):\n",
        "    flat = heatmap.flatten().reshape(-1, 1)\n",
        "    if np.std(flat) < 1e-5:\n",
        "        return np.zeros_like(heatmap, dtype=np.uint8)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto').fit(flat)\n",
        "    clustered = kmeans.labels_.reshape(heatmap.shape)\n",
        "    means = [np.mean(flat[kmeans.labels_ == i]) for i in range(n_clusters)]\n",
        "    sorted_indices = np.argsort(means)\n",
        "    label_map = np.zeros_like(clustered)\n",
        "    for new_label, original_label in enumerate(sorted_indices):\n",
        "        label_map[clustered == original_label] = new_label\n",
        "    return label_map.astype(np.uint8)\n",
        "\n",
        "# Function: Overlay Clustered Attention\n",
        "def overlay_clustered_attention(image_np, cluster_mask):\n",
        "    output = image_np.copy()\n",
        "    colors = {\n",
        "        0: [180, 180, 180],  # background (gray)\n",
        "        1: [255, 165, 0],    # uncertain (orange)\n",
        "        2: [255, 0, 0]       # lesion (red)\n",
        "    }\n",
        "    for region, color in colors.items():\n",
        "        mask = (cluster_mask == region)\n",
        "        for c in range(3):\n",
        "            output[:, :, c] = np.where(\n",
        "                mask,\n",
        "                0.5 * output[:, :, c] + 0.5 * color[c],\n",
        "                output[:, :, c]\n",
        "            )\n",
        "    return output.astype(np.uint8)\n",
        "\n",
        "# MAIN: Visualize 5 Test Images Side-by-Side\n",
        "plt.figure(figsize=(10, 10))\n",
        "input_height, input_width = model.input_shape[1], model.input_shape[2]\n",
        "count = 0\n",
        "\n",
        "for image, label in test_ds.unbatch().take(5):\n",
        "    image_resized = tf.image.resize(image, (input_height, input_width))\n",
        "    image_resized = tf.cast(image_resized, tf.float32)\n",
        "    image_batch = tf.expand_dims(image_resized, axis=0)\n",
        "    preds = model.predict(image_batch, verbose=0)[0]\n",
        "    pred_idx = np.argmax(preds)\n",
        "    confidence = round(100 * preds[pred_idx], 2)\n",
        "    pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "\n",
        "    # Grad-CAM and masking\n",
        "    heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "    heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "    image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "    leaf_mask = mask_leaf(image_np)\n",
        "    heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n",
        "    cluster_mask = apply_three_way_kmeans(heatmap_masked)\n",
        "    cluster_mask = cv2.resize(cluster_mask.astype(np.uint8), (input_width, input_height), interpolation=cv2.INTER_NEAREST)\n",
        "    overlayed_image = overlay_clustered_attention(image_np, cluster_mask)\n",
        "\n",
        "    # Plot original + clustered Grad-CAM side-by-side\n",
        "    plt.subplot(5, 2, 2 * count + 1)\n",
        "    plt.imshow(image_np)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(5, 2, 2 * count + 2)\n",
        "    plt.imshow(overlayed_image)\n",
        "    plt.title(f\"Clustered Attention\\n{pred_label} ({confidence}%)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    count += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:28:38.464813Z",
          "iopub.execute_input": "2025-07-01T02:28:38.465658Z",
          "iopub.status.idle": "2025-07-01T02:28:40.172801Z",
          "shell.execute_reply.started": "2025-07-01T02:28:38.46563Z",
          "shell.execute_reply": "2025-07-01T02:28:40.171985Z"
        },
        "id": "55UTLTro_yY4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 20))\n",
        "input_height, input_width = model.input_shape[1], model.input_shape[2]\n",
        "count = 0\n",
        "\n",
        "for image, label in test_ds.unbatch().take(10):\n",
        "    image_resized = tf.image.resize(image, (input_height, input_width))\n",
        "    image_resized = tf.cast(image_resized, tf.float32)\n",
        "    image_batch = tf.expand_dims(image_resized, axis=0)\n",
        "    preds = model.predict(image_batch, verbose=0)[0]\n",
        "    pred_idx = np.argmax(preds)\n",
        "    confidence = round(100 * preds[pred_idx], 2)\n",
        "    pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "\n",
        "    # Grad-CAM + masking\n",
        "    heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "    heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "    image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "    leaf_mask = mask_leaf(image_np)\n",
        "    heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n",
        "    cluster_mask = apply_three_way_kmeans(heatmap_masked)\n",
        "    cluster_mask = cv2.resize(cluster_mask.astype(np.uint8), (input_width, input_height), interpolation=cv2.INTER_NEAREST)\n",
        "    overlayed_image = overlay_clustered_attention(image_np, cluster_mask)\n",
        "\n",
        "    # Plot side-by-side\n",
        "    plt.subplot(10, 2, 2 * count + 1)\n",
        "    plt.imshow(image_np)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(10, 2, 2 * count + 2)\n",
        "    plt.imshow(overlayed_image)\n",
        "    plt.title(f\"Overlay - {pred_label} ({confidence}%)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    count += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:39:22.811463Z",
          "iopub.execute_input": "2025-07-01T02:39:22.812123Z",
          "iopub.status.idle": "2025-07-01T02:39:25.583873Z",
          "shell.execute_reply.started": "2025-07-01T02:39:22.812097Z",
          "shell.execute_reply": "2025-07-01T02:39:25.58296Z"
        },
        "id": "Wt_UE643_yY4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lesion_pixels = np.sum(cluster_mask == 2)\n",
        "uncertain_pixels = np.sum(cluster_mask == 1)\n",
        "background_pixels = np.sum(cluster_mask == 0)\n",
        "leaf_pixels = np.sum(leaf_mask == 255)\n",
        "\n",
        "lesion_ratio = round((lesion_pixels / leaf_pixels) * 100, 2)\n",
        "print(f\"[{count}] Lesion focus: {lesion_ratio}% of leaf area\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:40:21.658952Z",
          "iopub.execute_input": "2025-07-01T02:40:21.659287Z",
          "iopub.status.idle": "2025-07-01T02:40:21.665329Z",
          "shell.execute_reply.started": "2025-07-01T02:40:21.659264Z",
          "shell.execute_reply": "2025-07-01T02:40:21.664743Z"
        },
        "id": "foDz1H8__yY5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Prepare containers\n",
        "good_samples = []\n",
        "bad_samples = []\n",
        "\n",
        "# Model input\n",
        "input_height, input_width = model.input_shape[1], model.input_shape[2]\n",
        "\n",
        "# Loop through test set\n",
        "for image, label in test_ds.unbatch().take(100):  # Scan up to 100\n",
        "    image_resized = tf.image.resize(image, (input_height, input_width))\n",
        "    image_resized = tf.cast(image_resized, tf.float32)\n",
        "    image_batch = tf.expand_dims(image_resized, axis=0)\n",
        "    preds = model.predict(image_batch, verbose=0)[0]\n",
        "    pred_idx = np.argmax(preds)\n",
        "    confidence = round(100 * preds[pred_idx], 2)\n",
        "    pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "\n",
        "    # Grad-CAM\n",
        "    heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "    heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "    image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "\n",
        "    # Mask + Clustering\n",
        "    leaf_mask = mask_leaf(image_np)\n",
        "    heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n",
        "    cluster_mask = apply_three_way_kmeans(heatmap_masked)\n",
        "    cluster_mask = cv2.resize(cluster_mask.astype(np.uint8), (input_width, input_height), interpolation=cv2.INTER_NEAREST)\n",
        "    overlayed_image = overlay_clustered_attention(image_np, cluster_mask)\n",
        "\n",
        "    # Calculate lesion attention ratio\n",
        "    lesion_pixels = np.sum(cluster_mask == 2)\n",
        "    leaf_pixels = np.sum(leaf_mask == 255)\n",
        "    if leaf_pixels == 0:\n",
        "        continue\n",
        "    lesion_ratio = (lesion_pixels / leaf_pixels) * 100\n",
        "\n",
        "    # Decide if it's good or bad\n",
        "    if 10 <= lesion_ratio <= 45:\n",
        "        good_samples.append((image_np, overlayed_image, pred_label, confidence, lesion_ratio))\n",
        "    elif lesion_ratio < 5 or lesion_ratio > 70:\n",
        "        bad_samples.append((image_np, overlayed_image, pred_label, confidence, lesion_ratio))\n",
        "\n",
        "    # Stop if we have enough\n",
        "    if len(good_samples) >= 3 and len(bad_samples) >= 3:\n",
        "        break\n",
        "\n",
        "# Plot figure\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(3):\n",
        "    # Good sample row\n",
        "    img_orig, img_overlay, label, conf, ratio = good_samples[i]\n",
        "    plt.subplot(3, 4, 4*i + 1)\n",
        "    plt.imshow(img_orig)\n",
        "    plt.title(f\"Good-{i+1}: Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(3, 4, 4*i + 2)\n",
        "    plt.imshow(img_overlay)\n",
        "    plt.title(f\"{label} ({conf}%)\\nLesion: {round(ratio, 1)}%\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Bad sample row\n",
        "    img_orig, img_overlay, label, conf, ratio = bad_samples[i]\n",
        "    plt.subplot(3, 4, 4*i + 3)\n",
        "    plt.imshow(img_orig)\n",
        "    plt.title(f\"Bad-{i+1}: Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(3, 4, 4*i + 4)\n",
        "    plt.imshow(img_overlay)\n",
        "    plt.title(f\"{label} ({conf}%)\\nLesion: {round(ratio, 1)}%\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Good vs Bad Grad-CAM Interpretability (3-Way Clustering)\", fontsize=16, y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:51:11.299299Z",
          "iopub.execute_input": "2025-07-01T02:51:11.299611Z",
          "iopub.status.idle": "2025-07-01T02:51:15.976603Z",
          "shell.execute_reply.started": "2025-07-01T02:51:11.299589Z",
          "shell.execute_reply": "2025-07-01T02:51:15.975535Z"
        },
        "id": "Qw3L865A_yY5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.savefig(\"/kaggle/working/good_vs_bad_gradcam.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:58:09.886428Z",
          "iopub.execute_input": "2025-07-01T02:58:09.887436Z",
          "iopub.status.idle": "2025-07-01T02:58:09.992344Z",
          "shell.execute_reply.started": "2025-07-01T02:58:09.887402Z",
          "shell.execute_reply": "2025-07-01T02:58:09.991585Z"
        },
        "id": "FAyRtTPz_yY5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the class and get confidence\n",
        "image_resized = tf.image.resize(input_image, (input_height, input_width))\n",
        "image_resized = tf.convert_to_tensor(image_resized, dtype=tf.float32)\n",
        "image_resized = tf.ensure_shape(image_resized, [input_height, input_width, 3])  # Ensure shape\n",
        "\n",
        "# Expand dimensions for batch input\n",
        "image_batch = tf.expand_dims(image_resized, axis=0)\n",
        "\n",
        "# Run model prediction\n",
        "preds = model.predict(image_batch, verbose=0)[0]\n",
        "pred_idx = np.argmax(preds)\n",
        "confidence = round(100 * preds[pred_idx], 2)\n",
        "pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "\n",
        "# Grad-CAM generation\n",
        "heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "\n",
        "# Convert to NumPy for OpenCV\n",
        "image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "if image_np.shape[-1] == 1:\n",
        "    image_np = np.repeat(image_np, 3, axis=-1)\n",
        "\n",
        "# Generate the leaf mask\n",
        "leaf_mask = mask_leaf(image_np)\n",
        "\n",
        "# Apply the mask to Grad-CAM\n",
        "heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(image_np)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(heatmap_resized, cmap='plasma')\n",
        "plt.title(\"Grad-CAM (Full)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(heatmap_masked, cmap='plasma')\n",
        "plt.title(\"Grad-CAM (Masked)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:15:21.201759Z",
          "iopub.execute_input": "2025-07-01T02:15:21.202411Z",
          "iopub.status.idle": "2025-07-01T02:15:21.22205Z",
          "shell.execute_reply.started": "2025-07-01T02:15:21.202378Z",
          "shell.execute_reply": "2025-07-01T02:15:21.221164Z"
        },
        "id": "tWFtjI7o_yY5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def mask_leaf(image):\n",
        "    \"\"\"\n",
        "    Takes a NumPy RGB image (0â€“255) and returns a binary mask of the leaf area.\n",
        "    \"\"\"\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Define green color range in HSV (tune if needed)\n",
        "    lower_green = np.array([25, 40, 40])\n",
        "    upper_green = np.array([85, 255, 255])\n",
        "\n",
        "    # Create a mask for green regions\n",
        "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "    # Optional: clean noise using morphological operations\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    return mask  # dtype=uint8, shape=(H, W), values in {0, 255}\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:05:03.523152Z",
          "iopub.execute_input": "2025-07-01T02:05:03.523509Z",
          "iopub.status.idle": "2025-07-01T02:05:03.529173Z",
          "shell.execute_reply.started": "2025-07-01T02:05:03.523484Z",
          "shell.execute_reply": "2025-07-01T02:05:03.528329Z"
        },
        "id": "PUd0yBLD_yY6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Predict class and confidence\n",
        "preds = model.predict(tf.expand_dims(image_resized, axis=0), verbose=0)[0]\n",
        "pred_idx = np.argmax(preds)\n",
        "confidence = round(100 * preds[pred_idx], 2)\n",
        "pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "\n",
        "# 2. Generate Grad-CAM\n",
        "heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "\n",
        "# 3. Resize heatmap to match image dimensions\n",
        "heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "\n",
        "# 4. Convert image to NumPy for OpenCV\n",
        "image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "if image_np.shape[-1] == 1:\n",
        "    image_np = np.repeat(image_np, 3, axis=-1)\n",
        "\n",
        "# 5. Generate leaf-only mask using HSV color filtering\n",
        "leaf_mask = mask_leaf(image_np)  # Output shape: (H, W), values: 0 or 255\n",
        "\n",
        "# 6. Apply the mask to the Grad-CAM heatmap\n",
        "heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T02:07:29.547904Z",
          "iopub.execute_input": "2025-07-01T02:07:29.548627Z",
          "iopub.status.idle": "2025-07-01T02:07:29.565123Z",
          "shell.execute_reply.started": "2025-07-01T02:07:29.548601Z",
          "shell.execute_reply": "2025-07-01T02:07:29.564133Z"
        },
        "id": "NIP4ZbUb_yY6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Grad-CAM\n",
        "heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "\n",
        "# Resize heatmap to original image size\n",
        "heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "\n",
        "# Convert image to uint8 for OpenCV\n",
        "image_np = (image_resized.numpy() * 255).astype(np.uint8)\n",
        "\n",
        "# Generate mask for leaf only\n",
        "leaf_mask = mask_leaf(image_np)\n",
        "\n",
        "# Apply the mask: keep only values on the leaf\n",
        "heatmap_masked = np.where(leaf_mask == 255, heatmap_resized, 0)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:54:39.635622Z",
          "iopub.execute_input": "2025-07-01T01:54:39.63617Z",
          "iopub.status.idle": "2025-07-01T01:54:39.652935Z",
          "shell.execute_reply.started": "2025-07-01T01:54:39.636134Z",
          "shell.execute_reply": "2025-07-01T01:54:39.651968Z"
        },
        "id": "zOz5jZWu_yY6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three way k means"
      ],
      "metadata": {
        "id": "vggcBHZx_yY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_three_way_kmeans(heatmap, n_clusters=3):\n",
        "    flat = heatmap.flatten().reshape(-1, 1)\n",
        "\n",
        "    # Early exit: if all values are nearly the same\n",
        "    if np.std(flat) < 1e-5:\n",
        "        return np.zeros_like(heatmap, dtype=np.uint8)  # fallback: all background\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto').fit(flat)\n",
        "    clustered = kmeans.labels_.reshape(heatmap.shape)\n",
        "\n",
        "    # Sort cluster labels by average intensity\n",
        "    means = [np.mean(flat[kmeans.labels_ == i]) for i in range(n_clusters)]\n",
        "    sorted_indices = np.argsort(means)\n",
        "\n",
        "    label_map = np.zeros_like(clustered)\n",
        "    for new_label, old_label in enumerate(sorted_indices):\n",
        "        label_map[clustered == old_label] = new_label\n",
        "\n",
        "    return label_map.astype(np.uint8)  # 0=background, 1=uncertain, 2=lesion\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:25:05.097076Z",
          "iopub.execute_input": "2025-07-01T01:25:05.097782Z",
          "iopub.status.idle": "2025-07-01T01:25:05.104198Z",
          "shell.execute_reply.started": "2025-07-01T01:25:05.097756Z",
          "shell.execute_reply": "2025-07-01T01:25:05.103284Z"
        },
        "id": "RlfH9hpc_yY7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def overlay_clustered_attention(image, cluster_mask):\n",
        "    image_np = (image.numpy() * 255).astype(np.uint8)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "\n",
        "    # Define color mapping: background (gray), uncertain (orange), strong (red)\n",
        "    colors = {\n",
        "        0: [180, 180, 180],   # background\n",
        "        1: [255, 165, 0],     # uncertain\n",
        "        2: [255, 0, 0]        # strong attention\n",
        "    }\n",
        "\n",
        "    overlay = image_np.copy()\n",
        "    for region, color in colors.items():\n",
        "        mask = (cluster_mask == region)\n",
        "        for c in range(3):\n",
        "            overlay[:, :, c] = np.where(\n",
        "                mask,\n",
        "                0.5 * overlay[:, :, c] + 0.5 * color[c],\n",
        "                overlay[:, :, c]\n",
        "            )\n",
        "\n",
        "    return overlay.astype(np.uint8)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:25:09.038583Z",
          "iopub.execute_input": "2025-07-01T01:25:09.038863Z",
          "iopub.status.idle": "2025-07-01T01:25:09.044023Z",
          "shell.execute_reply.started": "2025-07-01T01:25:09.038844Z",
          "shell.execute_reply": "2025-07-01T01:25:09.043364Z"
        },
        "id": "j8Sxuf8V_yY7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_visualize_overlay(model, test_ds, class_names):\n",
        "    target_labels = {\"Healthy\", \"Early Blight\", \"Late Blight\"}\n",
        "    selected = {}\n",
        "    for image, label in test_ds.unbatch():\n",
        "        label_idx = label.numpy() if isinstance(label.numpy(), np.integer) else np.argmax(label.numpy())\n",
        "        class_name = class_names[label_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "        if class_name in target_labels and class_name not in selected:\n",
        "            selected[class_name] = (image, label_idx)\n",
        "        if len(selected) == len(target_labels):\n",
        "            break\n",
        "    if len(selected) < 3:\n",
        "        raise ValueError(f\"Missing classes: {set(target_labels) - set(selected)}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 12))\n",
        "    for i, class_name in enumerate([\"Healthy\", \"Early Blight\", \"Late Blight\"]):\n",
        "        image, true_idx = selected[class_name]\n",
        "        image_resized = tf.image.resize(image, (input_height, input_width))\n",
        "        preds = model.predict(tf.expand_dims(image_resized, axis=0), verbose=0)[0]\n",
        "        pred_idx = np.argmax(preds)\n",
        "        pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "        confidence = round(100 * preds[pred_idx], 2)\n",
        "\n",
        "        # Generate Grad-CAM\n",
        "        heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "\n",
        "        # Cluster the heatmap\n",
        "        cluster_mask = apply_three_way_kmeans(heatmap)\n",
        "\n",
        "        cluster_mask = cv2.resize(cluster_mask.astype(np.uint8), (input_width, input_height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "\n",
        "        # Overlay clustered mask\n",
        "        overlayed_cluster = overlay_clustered_attention(image_resized, cluster_mask)\n",
        "\n",
        "        # Plot original image\n",
        "        ax1 = plt.subplot(3, 2, 2 * i + 1)\n",
        "        ax1.imshow(image_resized.numpy().astype(\"float32\"))\n",
        "        ax1.axis(\"off\")\n",
        "        ax1.set_title(f\"True: {class_name}\", fontsize=10)\n",
        "\n",
        "        # Plot clustered attention\n",
        "        ax2 = plt.subplot(3, 2, 2 * i + 2)\n",
        "        ax2.imshow(overlayed_cluster)\n",
        "        ax2.axis(\"off\")\n",
        "        ax2.set_title(f\"Predicted: {pred_label} ({confidence}%)\", fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:25:58.110575Z",
          "iopub.execute_input": "2025-07-01T01:25:58.111107Z",
          "iopub.status.idle": "2025-07-01T01:25:58.119357Z",
          "shell.execute_reply.started": "2025-07-01T01:25:58.111083Z",
          "shell.execute_reply": "2025-07-01T01:25:58.118578Z"
        },
        "id": "yEro9Znc_yY7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_visualize_overlay(model, test_ds, class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:44:44.577433Z",
          "iopub.execute_input": "2025-07-01T01:44:44.578012Z",
          "iopub.status.idle": "2025-07-01T01:44:46.013538Z",
          "shell.execute_reply.started": "2025-07-01T01:44:44.577988Z",
          "shell.execute_reply": "2025-07-01T01:44:46.012872Z"
        },
        "id": "ZaJaPApe_yY8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grad CAM#"
      ],
      "metadata": {
        "id": "AUJpgdOD_yY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model(\"/kaggle/working/models/lightweight_cnn_20250625-011416.h5\")\n",
        "model.trainable = False  # Ensure BatchNorm and Dropout act in inference mode\n",
        "input_height, input_width = model.input_shape[1], model.input_shape[2]\n",
        "\n",
        "# Mid-level convolutional layer\n",
        "last_conv_layer = \"conv2d_4\"  # Double-check this with model.summary()\n",
        "\n",
        "# Generate Grad-CAM heatmap\n",
        "def generate_gradcam(model, image, class_index, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(tf.expand_dims(image, axis=0))\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)[0]\n",
        "    if grads is None:\n",
        "        raise ValueError(\"Gradients are None. Ensure model has trainable layers and correct conv layer.\")\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Generate overlay image\n",
        "def generate_gradcam_overlay(image, heatmap, alpha=0.5, colormap=cv2.COLORMAP_PLASMA, threshold=0.4):\n",
        "    # Convert heatmap to uint8 and apply color map\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "    color_heatmap = cv2.applyColorMap(heatmap_uint8, colormap)\n",
        "    color_heatmap = cv2.cvtColor(color_heatmap, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Convert image to uint8\n",
        "    image_np = (image.numpy() * 255).astype(np.uint8)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "\n",
        "    # Resize heatmap to match image size\n",
        "    color_heatmap = cv2.resize(color_heatmap, (image_np.shape[1], image_np.shape[0]))\n",
        "    heatmap_resized = cv2.resize(heatmap, (image_np.shape[1], image_np.shape[0]))  # for mask\n",
        "\n",
        "    # Apply threshold-based blending\n",
        "    mask = heatmap_resized > threshold\n",
        "    blended = cv2.addWeighted(image_np, 1 - alpha, color_heatmap, alpha, 0)\n",
        "    overlayed = image_np.copy()\n",
        "    overlayed[mask] = blended[mask]\n",
        "\n",
        "    return overlayed\n",
        "\n",
        "\n",
        "# Visualize Grad-CAM for three target classes\n",
        "def predict_and_visualize_overlay(model, test_ds, class_names):\n",
        "    target_labels = {\"Healthy\", \"Early Blight\", \"Late Blight\"}\n",
        "    selected = {}\n",
        "    for image, label in test_ds.unbatch():\n",
        "        label_idx = label.numpy() if isinstance(label.numpy(), np.integer) else np.argmax(label.numpy())\n",
        "        class_name = class_names[label_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "        if class_name in target_labels and class_name not in selected:\n",
        "            selected[class_name] = (image, label_idx)\n",
        "        if len(selected) == len(target_labels):\n",
        "            break\n",
        "    if len(selected) < 3:\n",
        "        raise ValueError(f\"Missing classes: {set(target_labels) - set(selected)}\")\n",
        "\n",
        "    plt.figure(figsize=(10, 12))\n",
        "    for i, class_name in enumerate([\"Healthy\", \"Early Blight\", \"Late Blight\"]):\n",
        "        image, true_idx = selected[class_name]\n",
        "        image_resized = tf.image.resize(image, (input_height, input_width))\n",
        "        preds = model.predict(tf.expand_dims(image_resized, axis=0), verbose=0)[0]\n",
        "        pred_idx = np.argmax(preds)\n",
        "        pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "        confidence = round(100 * preds[pred_idx], 2)\n",
        "\n",
        "        # Generate Grad-CAM\n",
        "        heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "\n",
        "        # Overlay\n",
        "        overlayed_image = generate_gradcam_overlay(image_resized, heatmap, alpha=0.5, threshold=0.4)\n",
        "\n",
        "        # Plot original\n",
        "        ax1 = plt.subplot(3, 2, 2 * i + 1)\n",
        "        ax1.imshow(image_resized.numpy().astype(\"float32\"))\n",
        "        ax1.axis(\"off\")\n",
        "        ax1.set_title(f\"True: {class_name}\", fontsize=10)\n",
        "\n",
        "        # Plot Grad-CAM overlay\n",
        "        ax2 = plt.subplot(3, 2, 2 * i + 2)\n",
        "        im = ax2.imshow(overlayed_image)\n",
        "        ax2.axis(\"off\")\n",
        "        ax2.set_title(f\"Predicted: {pred_label} ({confidence}%)\", fontsize=9)\n",
        "        cbar = plt.colorbar(\n",
        "            plt.cm.ScalarMappable(cmap=\"plasma\", norm=plt.Normalize(vmin=0, vmax=1)),\n",
        "            ax=ax2, fraction=0.046, pad=0.04\n",
        "        )\n",
        "        cbar.set_label(\"Model Attention\", fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:15:23.804646Z",
          "iopub.execute_input": "2025-07-01T01:15:23.805368Z",
          "iopub.status.idle": "2025-07-01T01:15:23.896183Z",
          "shell.execute_reply.started": "2025-07-01T01:15:23.805342Z",
          "shell.execute_reply": "2025-07-01T01:15:23.895603Z"
        },
        "id": "JAMnZKmQ_yY8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_visualize_overlay(model, test_ds, class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:15:25.250722Z",
          "iopub.execute_input": "2025-07-01T01:15:25.25118Z",
          "iopub.status.idle": "2025-07-01T01:15:27.161289Z",
          "shell.execute_reply.started": "2025-07-01T01:15:25.251157Z",
          "shell.execute_reply": "2025-07-01T01:15:27.160763Z"
        },
        "id": "GwRMehdL_yY9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, (input_height, input_width)), y))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:15:36.019217Z",
          "iopub.execute_input": "2025-07-01T01:15:36.019821Z",
          "iopub.status.idle": "2025-07-01T01:15:36.035167Z",
          "shell.execute_reply.started": "2025-07-01T01:15:36.019794Z",
          "shell.execute_reply": "2025-07-01T01:15:36.034386Z"
        },
        "id": "cX8DJFkH_yY-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_visualize_overlay(model, test_ds, class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:15:44.133018Z",
          "iopub.execute_input": "2025-07-01T01:15:44.133703Z",
          "iopub.status.idle": "2025-07-01T01:15:45.541655Z",
          "shell.execute_reply.started": "2025-07-01T01:15:44.133679Z",
          "shell.execute_reply": "2025-07-01T01:15:45.540654Z"
        },
        "id": "gwANMvM2_yY_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def apply_three_way_kmeans(heatmap, n_clusters=3):\n",
        "    flat = heatmap.flatten().reshape(-1, 1)\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(flat)\n",
        "    clustered = kmeans.labels_.reshape(heatmap.shape)\n",
        "\n",
        "    # Sort labels by mean value (e.g., 0 = low, 2 = high)\n",
        "    means = [np.mean(flat[kmeans.labels_ == i]) for i in range(n_clusters)]\n",
        "    sorted_idx = np.argsort(means)\n",
        "\n",
        "    label_map = np.zeros_like(clustered)\n",
        "    for new_label, old_label in enumerate(sorted_idx):\n",
        "        label_map[clustered == old_label] = new_label\n",
        "\n",
        "    return label_map  # 0 = negative, 1 = boundary, 2 = positive\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:16:27.714037Z",
          "iopub.execute_input": "2025-07-01T01:16:27.714318Z",
          "iopub.status.idle": "2025-07-01T01:16:27.964798Z",
          "shell.execute_reply.started": "2025-07-01T01:16:27.714299Z",
          "shell.execute_reply": "2025-07-01T01:16:27.964247Z"
        },
        "id": "fWM6zvlN_yZA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import cv2\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model(\"/kaggle/working/models/lightweight_cnn_20250625-011416.h5\")\n",
        "input_height, input_width = model.input_shape[1], model.input_shape[2]\n",
        "last_conv_layer = \"conv2d_2\"\n",
        "\n",
        "# Grad-CAM heatmap generator\n",
        "def generate_gradcam(model, image, class_index, last_conv_layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(tf.expand_dims(image, axis=0))\n",
        "        loss = predictions[:, class_index]\n",
        "    grads = tape.gradient(loss, conv_outputs)[0]\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-8)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Overlay only attention area\n",
        "def generate_gradcam_overlay(image, heatmap, alpha=0.5, colormap=cv2.COLORMAP_PLASMA, threshold=0.4):\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "    color_heatmap = cv2.applyColorMap(heatmap_uint8, colormap)\n",
        "    color_heatmap = cv2.cvtColor(color_heatmap, cv2.COLOR_BGR2RGB)\n",
        "    image_np = (image.numpy() * 255).astype(np.uint8)\n",
        "    if image_np.shape[-1] == 1:\n",
        "        image_np = np.repeat(image_np, 3, axis=-1)\n",
        "    mask = heatmap > threshold\n",
        "    overlayed = image_np.copy()\n",
        "    for c in range(3):\n",
        "        overlayed[:, :, c] = np.where(\n",
        "            mask,\n",
        "            cv2.addWeighted(image_np[:, :, c], 1 - alpha, color_heatmap[:, :, c], alpha, 0),\n",
        "            image_np[:, :, c]\n",
        "        )\n",
        "    return overlayed\n",
        "\n",
        "# Aligned horizontal layout with uniform spacing\n",
        "def predict_and_visualize_aligned_grid(model, test_ds, class_names):\n",
        "    target_labels = {\"Healthy\", \"Early Blight\", \"Late Blight\"}\n",
        "    selected = {}\n",
        "    for image, label in test_ds.unbatch():\n",
        "        label_idx = label.numpy() if isinstance(label.numpy(), np.integer) else np.argmax(label.numpy())\n",
        "        class_name = class_names[label_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "        if class_name in target_labels and class_name not in selected:\n",
        "            selected[class_name] = (image, label_idx)\n",
        "        if len(selected) == len(target_labels):\n",
        "            break\n",
        "    if len(selected) < 3:\n",
        "        raise ValueError(f\"Missing: {set(target_labels) - set(selected)}\")\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 6))\n",
        "    gs = gridspec.GridSpec(2, 3, figure=fig, hspace=0.15, wspace=0.1)\n",
        "\n",
        "    for col, class_name in enumerate([\"Early Blight\", \"Late Blight\", \"Healthy\"]):\n",
        "        image, true_idx = selected[class_name]\n",
        "        image_resized = tf.image.resize(image, (input_height, input_width))\n",
        "        preds = model.predict(tf.expand_dims(image_resized, axis=0), verbose=0)[0]\n",
        "        pred_idx = np.argmax(preds)\n",
        "        pred_label = class_names[pred_idx].split(\"___\")[-1].replace(\"_\", \" \").title()\n",
        "        confidence = round(100 * preds[pred_idx], 2)\n",
        "\n",
        "        heatmap = generate_gradcam(model, image_resized, pred_idx, last_conv_layer)\n",
        "        heatmap_resized = cv2.resize(heatmap, (input_width, input_height))\n",
        "        overlayed = generate_gradcam_overlay(image_resized, heatmap_resized)\n",
        "\n",
        "        # Row 0: Original Image\n",
        "        ax1 = fig.add_subplot(gs[0, col])\n",
        "        ax1.imshow(image_resized.numpy().astype(\"float32\"))\n",
        "        ax1.axis(\"off\")\n",
        "        ax1.set_title(\"Original Image\", fontsize=10)\n",
        "\n",
        "        # Row 1: Grad-CAM Overlay\n",
        "        ax2 = fig.add_subplot(gs[1, col])\n",
        "        im = ax2.imshow(overlayed)\n",
        "        ax2.axis(\"off\")\n",
        "        ax2.set_title(f\"{class_name} Class\\nPredicted: {pred_label} ({confidence}%)\", fontsize=9)\n",
        "\n",
        "        # Add colorbar (aligned right)\n",
        "        cbar = fig.colorbar(\n",
        "            plt.cm.ScalarMappable(cmap=\"plasma\", norm=plt.Normalize(vmin=0, vmax=1)),\n",
        "            ax=ax2, fraction=0.046, pad=0.03\n",
        "        )\n",
        "        cbar.set_label(\"Model Attention\", fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:18.161436Z",
          "iopub.execute_input": "2025-07-01T01:13:18.161649Z",
          "iopub.status.idle": "2025-07-01T01:13:18.251279Z",
          "shell.execute_reply.started": "2025-07-01T01:13:18.161633Z",
          "shell.execute_reply": "2025-07-01T01:13:18.250769Z"
        },
        "id": "Lr8t-HPe_yZA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, (input_height, input_width)), y))\n",
        "predict_and_visualize_aligned_grid(model, test_ds, class_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:18.251975Z",
          "iopub.execute_input": "2025-07-01T01:13:18.25223Z",
          "iopub.status.idle": "2025-07-01T01:13:19.98991Z",
          "shell.execute_reply.started": "2025-07-01T01:13:18.252208Z",
          "shell.execute_reply": "2025-07-01T01:13:19.989171Z"
        },
        "id": "jfqlCIkR_yZC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def generate_gradcam_heatmap(model, img_array, last_conv_layer_name):\n",
        "    grad_model = Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def create_binary_mask(heatmap, threshold=0.5):\n",
        "    binary_mask = (heatmap > threshold).astype(np.uint8)\n",
        "    return binary_mask\n",
        "\n",
        "def mask_background(image, binary_mask):\n",
        "    masked_image = image * np.expand_dims(binary_mask, axis=-1)\n",
        "    return masked_image.astype(np.uint8)\n",
        "\n",
        "def predict_and_visualize_gradcam_lime(model, image, class_names, last_conv_layer_name):\n",
        "    # Step 1: Generate Grad-CAM heatmap\n",
        "    img_array = tf.expand_dims(image, 0) / 255.0\n",
        "    heatmap = generate_gradcam_heatmap(model, img_array, last_conv_layer_name)\n",
        "\n",
        "    # Step 2: Create binary attention mask\n",
        "    binary_mask = create_binary_mask(heatmap)\n",
        "\n",
        "    # Step 3: Mask out the background\n",
        "    masked_image = mask_background((image * 255).astype(np.uint8), binary_mask)\n",
        "\n",
        "    # Step 4: Apply LIME on the masked image\n",
        "    explainer = lime_image.LimeImageExplainer(random_state=42)\n",
        "\n",
        "    def lime_predict_fn(images):\n",
        "        images_tf = tf.convert_to_tensor(images, dtype=tf.float32) / 255.0\n",
        "        return model.predict(images_tf)\n",
        "\n",
        "    explanation = explainer.explain_instance(\n",
        "        masked_image.astype('double'),\n",
        "        classifier_fn=lime_predict_fn,\n",
        "        top_labels=1,\n",
        "        hide_color=0,\n",
        "        num_samples=1000\n",
        "    )\n",
        "\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=0,\n",
        "        positive_only=False,\n",
        "        num_features=10,\n",
        "        hide_rest=False\n",
        "    )\n",
        "\n",
        "    lime_overlay = mark_boundaries(masked_image, mask, color=(1, 0, 0), mode='thick')\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.style.use('dark_background')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(masked_image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Masked Image\", color='white')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(lime_overlay)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"LIME Overlay\", color='white')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gradcam_lime.png')\n",
        "    plt.close()\n",
        "\n",
        "# Example usage (assuming model, image, class_names, and last_conv_layer_name are defined)\n",
        "# predict_and_visualize_gradcam_lime(model, image, class_names, 'last_conv_layer')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:19.990773Z",
          "iopub.execute_input": "2025-07-01T01:13:19.990988Z",
          "iopub.status.idle": "2025-07-01T01:13:20.665551Z",
          "shell.execute_reply.started": "2025-07-01T01:13:19.990971Z",
          "shell.execute_reply": "2025-07-01T01:13:20.664919Z"
        },
        "id": "ylzd6IGk_yZC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_visualize_lime_with_bg_removed(model, test_ds, class_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "P6TKX1XV_yZC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/kaggle/working/Custom_CNN.keras\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-01T01:13:20.698149Z",
          "iopub.status.idle": "2025-07-01T01:13:20.698495Z",
          "shell.execute_reply.started": "2025-07-01T01:13:20.698307Z",
          "shell.execute_reply": "2025-07-01T01:13:20.698323Z"
        },
        "id": "i2oJmMRK_yZD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "kGNcGORu_yZD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "bk_ZizAm_yZD"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}